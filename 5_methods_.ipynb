{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b946aaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This program calculates 5 methods for financial capitals.\n",
      "Choose an action:\n",
      "  [1] Run program based on input data \n",
      "  [2] Generate synthetic data\n",
      "Enter 1 or 2: 2\n",
      "Synthetic data is generated. Paths:\n",
      " - C:\\Users\\legio\\Documents\\transactions_template.csv\n",
      " - C:\\Users\\legio\\Documents\\financials_template.csv\n"
     ]
    }
   ],
   "source": [
    "# Author: Ferangiz Abdurakhmonova\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from scipy.stats import chi2\n",
    "    _HAS_SCIPY = True\n",
    "except Exception:\n",
    "    _HAS_SCIPY = False\n",
    "\n",
    "\n",
    "# -------------------------- Utility helpers -------------------------- #\n",
    "\n",
    "def safe_div(n: float | int, d: float | int) -> float:\n",
    "    try:\n",
    "        if d is None or pd.isna(d) or float(d) == 0.0:\n",
    "            return float('nan')\n",
    "        return float(n) / float(d)\n",
    "    except Exception:\n",
    "        return float('nan')\n",
    "\n",
    "\n",
    "def first_digit(x: float | int) -> Optional[int]:\n",
    "    if x is None or pd.isna(x):\n",
    "        return None\n",
    "    try:\n",
    "        v = abs(float(x))\n",
    "    except Exception:\n",
    "        return None\n",
    "    if v <= 0:\n",
    "        return None\n",
    "\n",
    "    s = f\"{v:.12g}\"\n",
    "    s = s.lstrip('0').lstrip('.')\n",
    "    for ch in s:\n",
    "        if ch.isdigit() and ch != '0':\n",
    "            return int(ch)\n",
    "        \n",
    "    while v < 1:\n",
    "        v *= 10\n",
    "    while v >= 10:\n",
    "        v /= 10\n",
    "    d = int(v)\n",
    "    return d if 1 <= d <= 9 else None\n",
    "\n",
    "\n",
    "# -------------------------- Benford -------------------------- #\n",
    "\n",
    "def compute_benford(df: pd.DataFrame, amount_col: str) -> Dict[str, object]:\n",
    "\n",
    "    if amount_col not in df.columns:\n",
    "        raise KeyError(f\"Amount column '{amount_col}' not in transactions DataFrame\")\n",
    "\n",
    "    digits = [first_digit(v) for v in df[amount_col].values]\n",
    "    digits = [d for d in digits if d is not None]\n",
    "    n = len(digits)\n",
    "    if n == 0:\n",
    "        raise ValueError(\"No positive numeric amounts found for Benford analysis\")\n",
    "\n",
    "    counts = np.array([digits.count(d) for d in range(1, 10)], dtype=float)\n",
    "    observed = counts / counts.sum()\n",
    "    expected = np.array([math.log10(1 + 1/d) for d in range(1, 10)], dtype=float)\n",
    "\n",
    "    mad = float(np.mean(np.abs(observed - expected)))\n",
    "\n",
    "    expected_counts = expected * n\n",
    "\n",
    "    chi2_stat = float(np.sum((counts - expected_counts) ** 2 / expected_counts))\n",
    "\n",
    "    if _HAS_SCIPY:\n",
    "\n",
    "        p_value = float(chi2.sf(chi2_stat, df=8))\n",
    "    else:\n",
    "        p_value = None\n",
    "\n",
    "    if mad < 0.006:\n",
    "        conformity = \"Close\"\n",
    "    elif mad < 0.012:\n",
    "        conformity = \"Acceptable\"\n",
    "    elif mad < 0.015:\n",
    "        conformity = \"Marginal\"\n",
    "    else:\n",
    "        conformity = \"Nonconformity\"\n",
    "\n",
    "    return {\n",
    "        \"expected_probs\": expected,\n",
    "        \"observed_probs\": observed,\n",
    "        \"counts\": counts.astype(int),\n",
    "        \"n\": n,\n",
    "        \"mad\": mad,\n",
    "        \"chi2\": chi2_stat,\n",
    "        \"p_value\": p_value,\n",
    "        \"conformity\": conformity,\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------- Beneish M-Score -------------------------- #\n",
    "\n",
    "def _beneish_components(curr: pd.Series, prev: pd.Series) -> Dict[str, float]:\n",
    "\n",
    "    Sales_t, Sales_p = curr.get(\"Sales\"), prev.get(\"Sales\")\n",
    "    COGS_t, COGS_p = curr.get(\"COGS\"), prev.get(\"COGS\")\n",
    "    AR_t, AR_p = curr.get(\"Receivables\"), prev.get(\"Receivables\")\n",
    "    CA_t, CA_p = curr.get(\"CurrentAssets\"), prev.get(\"CurrentAssets\")\n",
    "    PPE_t, PPE_p = curr.get(\"PPE\"), prev.get(\"PPE\")\n",
    "    TA_t, TA_p = curr.get(\"TotalAssets\"), prev.get(\"TotalAssets\")\n",
    "    Dep_t, Dep_p = curr.get(\"Depreciation\"), prev.get(\"Depreciation\")\n",
    "    SGA_t, SGA_p = curr.get(\"SGA\"), prev.get(\"SGA\")\n",
    "    TL_t, TL_p = curr.get(\"TotalLiabilities\"), prev.get(\"TotalLiabilities\")\n",
    "\n",
    "    dsri = safe_div(safe_div(AR_t, Sales_t), safe_div(AR_p, Sales_p))\n",
    "\n",
    "    gm_t = safe_div((Sales_t - COGS_t), Sales_t)\n",
    "    gm_p = safe_div((Sales_p - COGS_p), Sales_p)\n",
    "    gmi = safe_div(gm_p, gm_t)\n",
    "\n",
    "    aq_t = safe_div((TA_t - (CA_t + PPE_t)), TA_t)\n",
    "    aq_p = safe_div((TA_p - (CA_p + PPE_p)), TA_p)\n",
    "    aqi = safe_div(aq_t, aq_p)\n",
    "\n",
    "    sgi = safe_div(Sales_t, Sales_p)\n",
    "\n",
    "    dep_rate_t = safe_div(Dep_t, (PPE_t + Dep_t))\n",
    "    dep_rate_p = safe_div(Dep_p, (PPE_p + Dep_p))\n",
    "    depi = safe_div(dep_rate_p, dep_rate_t)\n",
    "\n",
    "    sgai = safe_div(safe_div(SGA_t, Sales_t), safe_div(SGA_p, Sales_p))\n",
    "\n",
    "    NI_t = curr.get(\"NetIncome\")\n",
    "    CFO_t = curr.get(\"CFO\")\n",
    "    tata = safe_div((NI_t - CFO_t), TA_t)\n",
    "\n",
    "    lvgi = safe_div(safe_div(TL_t, TA_t), safe_div(TL_p, TA_p))\n",
    "\n",
    "    return {\n",
    "        \"DSRI\": dsri, \"GMI\": gmi, \"AQI\": aqi, \"SGI\": sgi,\n",
    "        \"DEPI\": depi, \"SGAI\": sgai, \"TATA\": tata, \"LVGI\": lvgi\n",
    "    }\n",
    "\n",
    "\n",
    "def beneish_m_score(curr: pd.Series, prev: pd.Series) -> Tuple[float, Dict[str, float]]:\n",
    "    comps = _beneish_components(curr, prev)\n",
    "    m = (\n",
    "        -4.84\n",
    "        + 0.92 * comps[\"DSRI\"]\n",
    "        + 0.528 * comps[\"GMI\"]\n",
    "        + 0.404 * comps[\"AQI\"]\n",
    "        + 0.892 * comps[\"SGI\"]\n",
    "        + 0.115 * comps[\"DEPI\"]\n",
    "        - 0.172 * comps[\"SGAI\"]\n",
    "        + 4.679 * comps[\"TATA\"]\n",
    "        - 0.327 * comps[\"LVGI\"]\n",
    "    )\n",
    "    return m, comps\n",
    "\n",
    "\n",
    "# -------------------------- Altman Z (non-mfg) -------------------------- #\n",
    "\n",
    "def altman_z_non_mfg(curr: pd.Series) -> float:\n",
    "    CA = curr.get(\"CurrentAssets\")\n",
    "    CL = curr.get(\"CurrentLiabilities\")\n",
    "    TA = curr.get(\"TotalAssets\")\n",
    "    RE = curr.get(\"RetainedEarnings\", np.nan)\n",
    "    EBIT = curr.get(\"EBIT\")\n",
    "    TL = curr.get(\"TotalLiabilities\")\n",
    "    Equity = curr.get(\"ShareholdersEquity\", np.nan)\n",
    "\n",
    "    if pd.isna(RE):\n",
    "        pass\n",
    "\n",
    "    WC = None if (pd.isna(CA) or pd.isna(CL)) else (CA - CL)\n",
    "    X1 = safe_div(WC, TA)\n",
    "    X2 = safe_div(RE, TA)\n",
    "    X3 = safe_div(EBIT, TA)\n",
    "\n",
    "    if pd.isna(Equity):\n",
    "        if not pd.isna(TA) and not pd.isna(TL):\n",
    "            Equity = TA - TL\n",
    "    X4 = safe_div(Equity, TL)\n",
    "\n",
    "    z = 6.56 * X1 + 3.26 * X2 + 6.72 * X3 + 1.05 * X4\n",
    "    return z\n",
    "\n",
    "\n",
    "# -------------------------- Piotroski F-Score -------------------------- #\n",
    "\n",
    "def piotroski_f_score(curr: pd.Series, prev: pd.Series) -> Tuple[int, Dict[str, int]]:\n",
    "    TA_t, TA_p = curr.get(\"TotalAssets\"), prev.get(\"TotalAssets\")\n",
    "    NI_t, NI_p = curr.get(\"NetIncome\"), prev.get(\"NetIncome\")\n",
    "    CFO_t = curr.get(\"CFO\")\n",
    "\n",
    "    roa_t = safe_div(NI_t, TA_t)\n",
    "    roa_p = safe_div(NI_p, TA_p)\n",
    "    s1 = int(roa_t > 0)\n",
    "    s2 = int(CFO_t is not None and not pd.isna(CFO_t) and CFO_t > 0)\n",
    "    s3 = int(roa_t > roa_p)\n",
    "    s4 = int((CFO_t - NI_t) > 0) if (CFO_t is not None and not pd.isna(CFO_t) and NI_t is not None and not pd.isna(NI_t)) else 0\n",
    "\n",
    "    LTD_t = curr.get(\"LongTermDebt\", np.nan)\n",
    "    LTD_p = prev.get(\"LongTermDebt\", np.nan)\n",
    "    if pd.isna(LTD_t) or pd.isna(LTD_p):\n",
    "        lev_t = safe_div(curr.get(\"TotalLiabilities\"), TA_t)\n",
    "        lev_p = safe_div(prev.get(\"TotalLiabilities\"), TA_p)\n",
    "    else:\n",
    "        lev_t = safe_div(LTD_t, TA_t)\n",
    "        lev_p = safe_div(LTD_p, TA_p)\n",
    "\n",
    "    s5 = int(lev_t < lev_p) if (not pd.isna(lev_t) and not pd.isna(lev_p)) else 0\n",
    "\n",
    "    cr_t = safe_div(curr.get(\"CurrentAssets\"), curr.get(\"CurrentLiabilities\"))\n",
    "    cr_p = safe_div(prev.get(\"CurrentAssets\"), prev.get(\"CurrentLiabilities\"))\n",
    "    s6 = int(cr_t > cr_p) if (not pd.isna(cr_t) and not pd.isna(cr_p)) else 0\n",
    "\n",
    "    so_t = curr.get(\"SharesOutstanding\", np.nan)\n",
    "    so_p = prev.get(\"SharesOutstanding\", np.nan)\n",
    "    s7 = int(so_t <= so_p) if (not pd.isna(so_t) and not pd.isna(so_p)) else 0\n",
    "\n",
    "    Sales_t, Sales_p = curr.get(\"Sales\"), prev.get(\"Sales\")\n",
    "    COGS_t, COGS_p = curr.get(\"COGS\"), prev.get(\"COGS\")\n",
    "\n",
    "    gm_t = safe_div((Sales_t - COGS_t), Sales_t)\n",
    "    gm_p = safe_div((Sales_p - COGS_p), Sales_p)\n",
    "    s8 = int(gm_t > gm_p) if (not pd.isna(gm_t) and not pd.isna(gm_p)) else 0\n",
    "\n",
    "    at_t = safe_div(Sales_t, TA_t)\n",
    "    at_p = safe_div(Sales_p, TA_p)\n",
    "    s9 = int(at_t > at_p) if (not pd.isna(at_t) and not pd.isna(at_p)) else 0\n",
    "\n",
    "    parts = {f\"S{i}\": v for i, v in enumerate([s1, s2, s3, s4, s5, s6, s7, s8, s9], start=1)}\n",
    "    return int(sum(parts.values())), parts\n",
    "\n",
    "def earnings_quality(curr: pd.Series) -> float:\n",
    "    NI = curr.get(\"NetIncome\")\n",
    "    CFO = curr.get(\"CFO\")\n",
    "    return safe_div(CFO, NI)\n",
    "\n",
    "\n",
    "# -------------------------- Data model setup -------------------------- #\n",
    "REQUIRED_FINANCIALS = [\n",
    "    \"Company\", \"Period\", \"TotalAssets\", \"TotalLiabilities\", \"CurrentAssets\",\n",
    "    \"CurrentLiabilities\", \"Receivables\", \"Inventory\", \"PPE\", \"Depreciation\",\n",
    "    \"Sales\", \"COGS\", \"SGA\", \"EBIT\", \"NetIncome\", \"CFO\"\n",
    "]\n",
    "\n",
    "OPTIONAL_FINANCIALS = [\"LongTermDebt\", \"SharesOutstanding\", \"Intangibles\", \"ShareholdersEquity\", \"RetainedEarnings\"]\n",
    "\n",
    "TRANSACTION_COLS = [\"Company\", \"Date\", \"Amount\"]\n",
    "\n",
    "\n",
    "def create_synthetic_data(outdir: str = \".\") -> Tuple[str, str]:\n",
    "    outdir = os.path.abspath(outdir)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    tx_path = os.path.join(outdir, \"transactions_template.csv\")\n",
    "    fin_path = os.path.join(outdir, \"financials_template.csv\")\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"Company\": [\"ACME Inc\", \"ACME Inc\"],\n",
    "        \"Date\": [\"2024-12-01\", \"2024-12-02\"],\n",
    "        \"Amount\": [1250.75, 987.30],\n",
    "    }).to_csv(tx_path, index=False)\n",
    "\n",
    "    pd.DataFrame([\n",
    "        {\n",
    "            \"Company\": \"ACME Inc\", \"Period\": 2023, \"TotalAssets\": 1000000, \"TotalLiabilities\": 600000,\n",
    "            \"CurrentAssets\": 300000, \"CurrentLiabilities\": 200000, \"Receivables\": 80000, \"Inventory\": 120000,\n",
    "            \"PPE\": 400000, \"Depreciation\": 50000, \"Sales\": 900000, \"COGS\": 600000, \"SGA\": 120000,\n",
    "            \"EBIT\": 100000, \"NetIncome\": 70000, \"CFO\": 85000, \"LongTermDebt\": 300000,\n",
    "            \"SharesOutstanding\": 1000000, \"Intangibles\": 50000, \"ShareholdersEquity\": 400000, \"RetainedEarnings\": 150000\n",
    "        },\n",
    "        {\n",
    "            \"Company\": \"ACME Inc\", \"Period\": 2024, \"TotalAssets\": 1100000, \"TotalLiabilities\": 630000,\n",
    "            \"CurrentAssets\": 320000, \"CurrentLiabilities\": 210000, \"Receivables\": 90000, \"Inventory\": 130000,\n",
    "            \"PPE\": 450000, \"Depreciation\": 52000, \"Sales\": 950000, \"COGS\": 620000, \"SGA\": 130000,\n",
    "            \"EBIT\": 110000, \"NetIncome\": 76000, \"CFO\": 90000, \"LongTermDebt\": 310000,\n",
    "            \"SharesOutstanding\": 1000000, \"Intangibles\": 55000, \"ShareholdersEquity\": 470000, \"RetainedEarnings\": 180000\n",
    "        },\n",
    "    ]).to_csv(fin_path, index=False)\n",
    "\n",
    "    return tx_path, fin_path\n",
    "\n",
    "\n",
    "def read_csv_maybe(path: str) -> Optional[pd.DataFrame]:\n",
    "    if not path:\n",
    "        return None\n",
    "    if not os.path.exists(path):\n",
    "        print(\"No csv file was found\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if df.empty:\n",
    "            print(\"No csv file was found\")\n",
    "            return None\n",
    "        return df\n",
    "    except Exception:\n",
    "        print(\"No csv file was found\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def validate_financials_columns(df: pd.DataFrame) -> List[str]:\n",
    "    missing = [c for c in REQUIRED_FINANCIALS if c not in df.columns]\n",
    "    return missing\n",
    "\n",
    "\n",
    "def latest_pair_by_company(fin: pd.DataFrame) -> Dict[str, Tuple[pd.Series, pd.Series]]:\n",
    "    pairs: Dict[str, Tuple[pd.Series, pd.Series]] = {}\n",
    "    for comp, g in fin.groupby(\"Company\"):\n",
    "        gg = g.sort_values(\"Period\").dropna(subset=[\"Period\"])  # oldest -> newest\n",
    "        if len(gg) < 2:\n",
    "            continue\n",
    "        prev = gg.iloc[-2]\n",
    "        curr = gg.iloc[-1]\n",
    "        pairs[comp] = (curr, prev)\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def summarize_methods(\n",
    "    benford: Optional[Dict[str, object]],\n",
    "    company_rows: List[Dict[str, object]],\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    if benford is not None:\n",
    "        rows.append({\n",
    "            \"Method\": \"Benford's Compliance\",\n",
    "            \"Result\": f\"MAD={benford['mad']:.4f}; chi2={benford['chi2']:.2f}\" + (f\"; p={benford['p_value']:.4f}\" if benford['p_value'] is not None else \"\"),\n",
    "            \"Rule/Threshold\": \"MAD < 0.006 close; < 0.012 acceptable; < 0.015 marginal\",\n",
    "            \"Interpretation\": f\"{benford['conformity']} conformity\",\n",
    "            \"Notes\": f\"n={benford['n']} transactions; amount column analyzed\"\n",
    "        })\n",
    "\n",
    "    for row in company_rows:\n",
    "        rows.append({\n",
    "            \"Method\": f\"Beneish M-Score ({row['Company']})\",\n",
    "            \"Result\": f\"{row.get('MScore', np.nan):.3f}\",\n",
    "            \"Rule/Threshold\": \"Manipulation risk if M > -2.22\",\n",
    "            \"Interpretation\": \"Risk\" if (row.get('MScore', np.nan) > -2.22) else \"Low/Unknown\",\n",
    "            \"Notes\": \"Computed from two periods\"\n",
    "        })\n",
    "        rows.append({\n",
    "            \"Method\": f\"Altman Z (non-mfg) ({row['Company']})\",\n",
    "            \"Result\": f\"{row.get('AltmanZ', np.nan):.3f}\",\n",
    "            \"Rule/Threshold\": \"Distress < 1.1; Safe > 2.6\",\n",
    "            \"Interpretation\": (\n",
    "                \"Distress\" if row.get('AltmanZ', np.nan) < 1.1 else (\n",
    "                    \"Safe\" if row.get('AltmanZ', np.nan) > 2.6 else \"Grey\"\n",
    "                )\n",
    "            ),\n",
    "            \"Notes\": \"Per 4-factor model\"\n",
    "        })\n",
    "        rows.append({\n",
    "            \"Method\": f\"Piotroski F-Score ({row['Company']})\",\n",
    "            \"Result\": f\"{int(row.get('PiotroskiF', 0))}/9\",\n",
    "            \"Rule/Threshold\": \"Higher is stronger (0–9)\",\n",
    "            \"Interpretation\": (\n",
    "                \"Strong\" if row.get('PiotroskiF', 0) >= 7 else (\n",
    "                    \"Weak\" if row.get('PiotroskiF', 0) <= 3 else \"Neutral\"\n",
    "                )\n",
    "            ),\n",
    "            \"Notes\": \"9 binary signals\"\n",
    "        })\n",
    "        rows.append({\n",
    "            \"Method\": f\"Earnings Quality QoE ({row['Company']})\",\n",
    "            \"Result\": f\"{row.get('QoE', np.nan):.3f}\",\n",
    "            \"Rule/Threshold\": \"~1 or higher preferred; <1 may be weak\",\n",
    "            \"Interpretation\": (\n",
    "                \"Low\" if row.get('QoE', np.nan) < 1 else \"OK/High\"\n",
    "            ),\n",
    "            \"Notes\": \"CFO / NetIncome\"\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    print(\"This program calculates 5 methods for financial capitals.\")\n",
    "    print(\"Choose an action:\\n  [1] Run program based on input data \\n  [2] Generate synthetic data\")\n",
    "    action = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "    if action == \"2\":\n",
    "        tx_path, fin_path = create_synthetic_data()\n",
    "        print(f\"Synthetic data is generated. Paths:\\n - {tx_path}\\n - {fin_path}\")\n",
    "        return\n",
    "\n",
    "    if action != \"1\":\n",
    "        print(\"Exiting.\")\n",
    "        return \n",
    "\n",
    "    fin_path = input(\"Path to FINANCIALS input data (format: .csv (leave blank to skip): \").strip()\n",
    "    tx_path = input(\"Path to TRANSACTIONS input data for Benford (format: .csv (leave blank to skip): \").strip()\n",
    "\n",
    "    fin_df = read_csv_maybe(fin_path)\n",
    "    tx_df = read_csv_maybe(tx_path)\n",
    "\n",
    "    benford_result: Optional[Dict[str, object]] = None\n",
    "    company_rows: List[Dict[str, object]] = []\n",
    "\n",
    "    if tx_df is not None:\n",
    "        amount_col = None\n",
    " \n",
    "        for cand in [\"Amount\", \"amount\", \"AMOUNT\", \"Value\", \"value\"]:\n",
    "            if cand in tx_df.columns:\n",
    "                amount_col = cand\n",
    "                break\n",
    "        if not amount_col:\n",
    "            print(\"Columns available in transactions CSV:\", list(tx_df.columns))\n",
    "            amount_col = input(\"Enter the column name that holds transaction amounts: \").strip()\n",
    "        if amount_col not in tx_df.columns:\n",
    "            print(\"No csv file was found\")\n",
    "        else:\n",
    "            print(f\"Using transactions CSV: {tx_path}\")\n",
    "            print(f\"Amount column: {amount_col}\")\n",
    "            try:\n",
    "                benford_result = compute_benford(tx_df, amount_col)\n",
    "\n",
    "                observed = pd.DataFrame({\n",
    "                    \"Digit\": list(range(1, 10)),\n",
    "                    \"ExpectedProb\": benford_result[\"expected_probs\"],\n",
    "                    \"ObservedProb\": benford_result[\"observed_probs\"],\n",
    "                    \"Count\": benford_result[\"counts\"],\n",
    "                })\n",
    "                observed.to_csv(\"benford_details.csv\", index=False)\n",
    "            except Exception as e:\n",
    "                print(f\"Benford computation error: {e}\")\n",
    "\n",
    "\n",
    "    if fin_df is not None:\n",
    "        missing = validate_financials_columns(fin_df)\n",
    "        if missing:\n",
    "            print(\"Financials CSV is missing required columns:\", missing)\n",
    "            print(\"No csv file was found\")\n",
    "        else:\n",
    "            print(f\"Using financials CSV: {fin_path}\")\n",
    "            pairs = latest_pair_by_company(fin_df)\n",
    "            if not pairs:\n",
    "                print(\"No company has two periods — skipping financial-based methods.\")\n",
    "            for comp, (curr, prev) in pairs.items():\n",
    "                row: Dict[str, object] = {\"Company\": comp, \"Period\": curr.get(\"Period\")}\n",
    "\n",
    "                try:\n",
    "                    mscore, comps = beneish_m_score(curr, prev)\n",
    "                    row[\"MScore\"] = mscore\n",
    "                    for k, v in comps.items():\n",
    "                        row[k] = v\n",
    "                except Exception as e:\n",
    "                    row[\"MScore\"] = np.nan\n",
    "                    row[\"_beneish_error\"] = str(e)\n",
    "\n",
    "                try:\n",
    "                    row[\"AltmanZ\"] = altman_z_non_mfg(curr)\n",
    "                except Exception as e:\n",
    "                    row[\"AltmanZ\"] = np.nan\n",
    "                    row[\"_altman_error\"] = str(e)\n",
    "\n",
    "                try:\n",
    "                    f, parts = piotroski_f_score(curr, prev)\n",
    "                    row[\"PiotroskiF\"] = f\n",
    "                    for k, v in parts.items():\n",
    "                        row[f\"F_{k}\"] = v\n",
    "                except Exception as e:\n",
    "                    row[\"PiotroskiF\"] = np.nan\n",
    "                    row[\"_piotroski_error\"] = str(e)\n",
    "\n",
    "                try:\n",
    "                    row[\"QoE\"] = earnings_quality(curr)\n",
    "                except Exception as e:\n",
    "                    row[\"QoE\"] = np.nan\n",
    "                    row[\"_qoe_error\"] = str(e)\n",
    "\n",
    "                company_rows.append(row)\n",
    "\n",
    "            if company_rows:\n",
    "                pd.DataFrame(company_rows).to_csv(\"company_metrics.csv\", index=False)\n",
    "\n",
    "    if (tx_df is None) and (fin_df is None):\n",
    "        print(\"No csv file was found\")\n",
    "        return\n",
    "\n",
    "    summary = summarize_methods(benford_result, company_rows)\n",
    "    if summary.empty:\n",
    "        print(\"No results to display (insufficient data).\")\n",
    "        return\n",
    "\n",
    "    summary.to_csv(\"results_summary.csv\", index=False)\n",
    "\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_colwidth', 60):\n",
    "        print(\"\\n=== Results Summary (Table Style) ===\")\n",
    "        print(summary.to_string(index=False))\n",
    "        print(\"\\nSaved: results_summary.csv, company_metrics.csv, benford_details.csv (if applicable)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
